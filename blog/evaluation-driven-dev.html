<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Evaluation Driven Dev - Matouš Eibich</title>
    <link rel="stylesheet" href="../assets/css/styles.css">
    <meta property="og:title" content="Evaluation Driven Dev">
    <meta property="og:description" content="Why proper ML/AI evaluation practices are crucial for LLM product development.">
    <meta property="og:type" content="article">
    <meta name="author" content="Matouš Eibich">
    <meta property="article:published_time" content="2025-03-25">
</head>
<body>
    <div class="page-container">
        <header>
            <h1>Evaluation Driven Dev</h1>
            <div class="nav-links">
                <a href="../index.html" class="home-btn">Home</a>
                <a href="../blog.html" class="home-btn">Blog</a>
            </div>
        </header>
        <div class="content article">
            <div class="article-meta">
                <time datetime="2025-03-25">March 25, 2025</time>
                <span class="author">by Matouš Eibich</span>
            </div>
            
            <p>Evaluation driven development - IMO, the only sane way to do LLM product dev.</p>
            
            <p>So I don't really know what happened here, but it seems like people forgot how to do proper ML/AI evaluation the moment we started developing LLM products.</p>

            <p>Imagine that it's 2020. You're working on a nice juicy ML regression task (maybe predicting prices of vehicle insurance like I did). You train a new xgboost model and then you go show it to your senior colleague. He asks "nice, how are the test results" and you say "I tried 5 different vehicles (observations), vibe-checked it and the results seemed good".</p>

            <p class="emphasis">OK BRO. YOU FIRED.</p>

            <p>Now let's be honest, how many of you were/are testing LLM systems this way? I know I did when I started working with LLMs. But it makes 0 sense. You're still working with a predictive algorithm. You're still trying to cover as much of the outcome space as possible.</p>

            <p>That's why you should approach LLM testing exactly like any other ML app (well maybe not exactly exactly because of pre-training and all that but you get my point). This is called evaluation-driven development (previously known simply as "ML" because nobody imagined we'd screw it up this badly).</p>

            <p>This post is more conceptional (aka a rant). I'll post more technical stuff later. But until then, please, for the love of god, go create a proper test dataset.</p>
        </div>
    </div>
</body>
</html> 